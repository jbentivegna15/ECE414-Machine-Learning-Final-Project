{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ML Final Project Kaggle Competition\n",
    "#By Jeremiah Pratt and Joseph Bentivegna\n",
    "#Dedicated to my mother, who always withheld affection and told me I'd never make anything of myself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn import gaussian_process\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import robust_scale\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainyBoi = pd.read_csv('train.csv',header=None)\n",
    "testyBoi = pd.read_csv('test.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67\n",
      "0.615\n",
      "0.59\n",
      "0.565\n",
      "0.605\n",
      "0.56\n",
      "0.56\n",
      "0.63\n",
      "0.645\n",
      "0.665\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "scaler = MinMaxScaler()\n",
    "X = trainyBoi.iloc[:,1:]\n",
    "X = scaler.fit_transform(X)\n",
    "Y = trainyBoi.iloc[:,0]\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "logreg = linear_model.LogisticRegression(penalty='l2',C=1,solver='newton-cg',max_iter=1000)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    logreg.fit(X_train,Y_train)\n",
    "    print(logreg.score(X_test,Y_test))\n",
    "#print(metrics.confusion_matrix(Y_test,logreg.predict(X_test)))\n",
    "\n",
    "logreg.fit(X,Y)\n",
    "pred = pd.DataFrame(logreg.predict(testyBoi))\n",
    "pred.to_csv('results.csv',index_label=['Id','Prediction'],index=list(range(1,200)))\n",
    "\n",
    "#Playing with feature selection, doesn't really make it better\n",
    "sel = VarianceThreshold(threshold=(.9*(1-.9)))\n",
    "sel.fit_transform(X)\n",
    "logreg = linear_model.LogisticRegression(penalty='l2',C=1,solver='newton-cg',max_iter=1000)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    logreg.fit(X_train,Y_train)\n",
    "    print(logreg.score(X_test,Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.566\n",
      "0.472\n",
      "[[ 4 34  1  5  1  0  2  5  3  1]\n",
      " [ 1 39  0  1  2  0  0  1  1  1]\n",
      " [ 0 19  7  3  7  1  0  6  7  1]\n",
      " [ 0 12  0 28  0  0  1  4  0  1]\n",
      " [ 1 15  0  3 20  0  0  5  3  1]\n",
      " [ 0 20  0  1  0 37  0  0  0  0]\n",
      " [ 0 11  0  2  0  0 33  1  0  3]\n",
      " [ 0  8  0  0  0  0  0 34  0  2]\n",
      " [ 0 24  0  1  4  1  0  5  7  3]\n",
      " [ 0 16  0  1  1  1  0  9  1 27]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=1000, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=0.001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tried Stochastic Gradient Descent\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X = trainyBoi.iloc[:,1:]\n",
    "X = scaler.fit_transform(X)\n",
    "Y = trainyBoi.iloc[:,0]\n",
    "kf = KFold(n_splits=2, shuffle=True)\n",
    "SGD = linear_model.SGDClassifier(loss=\"log\",penalty=\"l2\",tol=1e-3,max_iter=1000)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    SGD.fit(X_train,Y_train)\n",
    "    print(SGD.score(X_test,Y_test))\n",
    "print(metrics.confusion_matrix(Y_test,SGD.predict(X_test)))\n",
    "SGD.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
